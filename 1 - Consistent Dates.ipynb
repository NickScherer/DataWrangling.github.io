{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Consistent Dates\n",
    "In this first Step I'll show you how to create consistent dates. You will always see: comment, then Python coding and follwed the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "df = pd.read_json(\"customer_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a quick look at the data with the <code>.head()</code> method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>frequently_bought_together</th>\n",
       "      <th>lat_lon</th>\n",
       "      <th>purchase</th>\n",
       "      <th>related_items</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.64</td>\n",
       "      <td>household</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>100191</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>towels</td>\n",
       "      <td>41.86,-87.619</td>\n",
       "      <td>soap</td>\n",
       "      <td>towels</td>\n",
       "      <td>IL</td>\n",
       "      <td>60605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>clothing</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>100199</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>sandals</td>\n",
       "      <td>32.924,-96.547</td>\n",
       "      <td>shorts</td>\n",
       "      <td>belts</td>\n",
       "      <td>TX</td>\n",
       "      <td>75089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.72</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>100170</td>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>lawn bags</td>\n",
       "      <td>40.002,-75.118</td>\n",
       "      <td>lawn_mower</td>\n",
       "      <td>shovels</td>\n",
       "      <td>PA</td>\n",
       "      <td>19019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.32</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>100124</td>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>headphones</td>\n",
       "      <td>41.88,-87.63</td>\n",
       "      <td>laptop</td>\n",
       "      <td>headphones</td>\n",
       "      <td>IL</td>\n",
       "      <td>60603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.75</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>100173</td>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>sponge</td>\n",
       "      <td>39.953,-75.166</td>\n",
       "      <td>car wash</td>\n",
       "      <td>sponge</td>\n",
       "      <td>PA</td>\n",
       "      <td>19102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  amount     category          city  customer_id       date  \\\n",
       "0  24.64    household       Chicago       100191 2014-01-01   \n",
       "1     35     clothing        Dallas       100199 2014-01-02   \n",
       "2  89.72      outdoor  Philadelphia       100170 2014-01-03   \n",
       "3  51.32  electronics       Chicago       100124 2014-01-04   \n",
       "4  81.75      outdoor  Philadelphia       100173 2014-01-05   \n",
       "\n",
       "  frequently_bought_together         lat_lon    purchase related_items state  \\\n",
       "0                     towels   41.86,-87.619        soap        towels    IL   \n",
       "1                    sandals  32.924,-96.547      shorts         belts    TX   \n",
       "2                  lawn bags  40.002,-75.118  lawn_mower       shovels    PA   \n",
       "3                 headphones    41.88,-87.63      laptop    headphones    IL   \n",
       "4                     sponge  39.953,-75.166    car wash        sponge    PA   \n",
       "\n",
       "   zip_code  \n",
       "0     60605  \n",
       "1     75089  \n",
       "2     19019  \n",
       "3     60603  \n",
       "4     19102  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original date format was changed, but I want to keep the original format. \n",
    "\n",
    "I'll import the data again, but this time set the <code>convert_dates</code> parameter to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>frequently_bought_together</th>\n",
       "      <th>lat_lon</th>\n",
       "      <th>purchase</th>\n",
       "      <th>related_items</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.64</td>\n",
       "      <td>household</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>100191</td>\n",
       "      <td>1-Jan-14</td>\n",
       "      <td>towels</td>\n",
       "      <td>41.86,-87.619</td>\n",
       "      <td>soap</td>\n",
       "      <td>towels</td>\n",
       "      <td>IL</td>\n",
       "      <td>60605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>clothing</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>100199</td>\n",
       "      <td>2-Jan-14</td>\n",
       "      <td>sandals</td>\n",
       "      <td>32.924,-96.547</td>\n",
       "      <td>shorts</td>\n",
       "      <td>belts</td>\n",
       "      <td>TX</td>\n",
       "      <td>75089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.72</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>100170</td>\n",
       "      <td>3-Jan-14</td>\n",
       "      <td>lawn bags</td>\n",
       "      <td>40.002,-75.118</td>\n",
       "      <td>lawn_mower</td>\n",
       "      <td>shovels</td>\n",
       "      <td>PA</td>\n",
       "      <td>19019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.32</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>100124</td>\n",
       "      <td>4-Jan-14</td>\n",
       "      <td>headphones</td>\n",
       "      <td>41.88,-87.63</td>\n",
       "      <td>laptop</td>\n",
       "      <td>headphones</td>\n",
       "      <td>IL</td>\n",
       "      <td>60603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.75</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>100173</td>\n",
       "      <td>5-Jan-14</td>\n",
       "      <td>sponge</td>\n",
       "      <td>39.953,-75.166</td>\n",
       "      <td>car wash</td>\n",
       "      <td>sponge</td>\n",
       "      <td>PA</td>\n",
       "      <td>19102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  amount     category          city  customer_id      date  \\\n",
       "0  24.64    household       Chicago       100191  1-Jan-14   \n",
       "1     35     clothing        Dallas       100199  2-Jan-14   \n",
       "2  89.72      outdoor  Philadelphia       100170  3-Jan-14   \n",
       "3  51.32  electronics       Chicago       100124  4-Jan-14   \n",
       "4  81.75      outdoor  Philadelphia       100173  5-Jan-14   \n",
       "\n",
       "  frequently_bought_together         lat_lon    purchase related_items state  \\\n",
       "0                     towels   41.86,-87.619        soap        towels    IL   \n",
       "1                    sandals  32.924,-96.547      shorts         belts    TX   \n",
       "2                  lawn bags  40.002,-75.118  lawn_mower       shovels    PA   \n",
       "3                 headphones    41.88,-87.63      laptop    headphones    IL   \n",
       "4                     sponge  39.953,-75.166    car wash        sponge    PA   \n",
       "\n",
       "   zip_code  \n",
       "0     60605  \n",
       "1     75089  \n",
       "2     19019  \n",
       "3     60603  \n",
       "4     19102  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"customer_data.json\", convert_dates=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the dates are in the day-month-year <code>%d-%b-%y</code> format. We can confirm this using the datetime method <code>.strptime()</code> which creates a datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Jan-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2014, 1, 1, 0, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[0]['date']\n",
    "print(y)\n",
    "\n",
    "# this is a datetime object\n",
    "datetime.datetime.strptime(y, '%d-%b-%y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the date entry does not match this format, we'll get a <code>ValueError</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '1-January-2014' does not match format '%d-%b-%y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b66fd0cbe194>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# this is a datetime object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%d-%b-%y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \"\"\"Return a class cls instance based on the input string and the\n\u001b[0;32m    564\u001b[0m     format string.\"\"\"\n\u001b[1;32m--> 565\u001b[1;33m     \u001b[0mtt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfraction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    566\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         raise ValueError(\"time data %r does not match format %r\" %\n\u001b[1;32m--> 362\u001b[1;33m                          (data_string, format))\n\u001b[0m\u001b[0;32m    363\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         raise ValueError(\"unconverted data remains: %s\" %\n",
      "\u001b[1;31mValueError\u001b[0m: time data '1-January-2014' does not match format '%d-%b-%y'"
     ]
    }
   ],
   "source": [
    "# example of an inconsistent date format\n",
    "x = '1-January-2014'\n",
    "\n",
    "# this is a datetime object\n",
    "datetime.datetime.strptime(x, '%d-%b-%y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the <code>.strptime()</code> method to check our date formats. If we get an error, we can collect those dates for later on. I'll also collect the index location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{98: '9-April-2014',\n",
       " 99: '10-April-2014',\n",
       " 100: '11-April-2014',\n",
       " 101: '12-April-2014',\n",
       " 102: '13-April-2014',\n",
       " 103: '14-April-2014',\n",
       " 104: '15-April-2014',\n",
       " 105: '16-April-2014',\n",
       " 106: '17-April-2014',\n",
       " 107: '18-April-2014',\n",
       " 108: '19-April-2014',\n",
       " 151: '6/1/2014',\n",
       " 152: '6/2/2014',\n",
       " 153: '6/3/2014',\n",
       " 154: '6/4/2014',\n",
       " 155: '6/5/2014',\n",
       " 156: '6/6/2014',\n",
       " 157: '6/7/2014',\n",
       " 158: '6/8/2014',\n",
       " 159: '6/9/2014',\n",
       " 160: '6/10/2014',\n",
       " 161: '6/11/2014',\n",
       " 243: '1-Sep-2014',\n",
       " 244: '2-Sep-2014',\n",
       " 245: '3-Sep-2014',\n",
       " 246: '4-Sep-2014',\n",
       " 247: '5-Sep-2014',\n",
       " 248: '6-Sep-2014',\n",
       " 249: '7-Sep-2014',\n",
       " 250: '8-Sep-2014',\n",
       " 251: '9-Sep-2014',\n",
       " 252: '10-Sep-2014',\n",
       " 253: '11-Sep-2014',\n",
       " 254: '12-Sep-2014',\n",
       " 255: '13-Sep-2014',\n",
       " 283: '10/11/2014',\n",
       " 284: '10/12/2014',\n",
       " 285: '10/13/2014',\n",
       " 286: '10/14/2014',\n",
       " 287: '10/15/2014',\n",
       " 288: '10/16/2014',\n",
       " 289: '10/17/2014',\n",
       " 290: '10/18/2014',\n",
       " 291: '10/19/2014',\n",
       " 292: '10/20/2014',\n",
       " 293: '10/21/2014',\n",
       " 294: '10/22/2014',\n",
       " 295: '10/23/2014',\n",
       " 296: '10/24/2014',\n",
       " 297: '10/25/2014',\n",
       " 298: '10/26/2014',\n",
       " 299: '10/27/2014',\n",
       " 300: '10/28/2014',\n",
       " 301: '10/29/2014',\n",
       " 302: '10/30/2014',\n",
       " 303: '10/31/2014',\n",
       " 304: '11/1/2014',\n",
       " 305: '11/2/2014',\n",
       " 306: '11/3/2014',\n",
       " 307: '11/4/2014',\n",
       " 308: '11/5/2014',\n",
       " 309: '11/6/2014',\n",
       " 577: '1-August-2015',\n",
       " 578: '2-August-2015',\n",
       " 579: '3-August-2015',\n",
       " 580: '4-August-2015',\n",
       " 581: '5-August-2015',\n",
       " 582: '6-August-2015',\n",
       " 583: '7-August-2015',\n",
       " 584: '8-August-2015',\n",
       " 585: '9-August-2015',\n",
       " 586: '10-August-2015',\n",
       " 587: '11-August-2015',\n",
       " 588: '12-August-2015',\n",
       " 589: '13-August-2015',\n",
       " 590: '14-August-2015',\n",
       " 591: '15-August-2015',\n",
       " 799: '3/10/16',\n",
       " 800: '3/11/16',\n",
       " 801: '3/12/16',\n",
       " 802: '3/13/16',\n",
       " 803: '3/14/16',\n",
       " 804: '3/15/16',\n",
       " 805: '3/16/16',\n",
       " 806: '3/17/16',\n",
       " 807: '3/18/16',\n",
       " 808: '3/19/16',\n",
       " 809: '3/20/16',\n",
       " 810: '3/21/16',\n",
       " 1127: '2/1/2017',\n",
       " 1128: '2/2/2017',\n",
       " 1129: '2/3/2017',\n",
       " 1130: '2/4/2017',\n",
       " 1131: '2/5/2017',\n",
       " 1132: '2/6/2017',\n",
       " 1133: '2/7/2017',\n",
       " 1134: '2/8/2017',\n",
       " 1135: '2/9/2017',\n",
       " 1136: '2/10/2017',\n",
       " 1137: '2/11/2017',\n",
       " 1138: '2/12/2017',\n",
       " 1139: '2/13/2017',\n",
       " 1140: '2/14/2017',\n",
       " 1141: '2/15/2017',\n",
       " 1142: '2/16/2017',\n",
       " 1143: '2/17/2017',\n",
       " 1144: '2/18/2017',\n",
       " 1664: '7/23/2018',\n",
       " 1665: '7/24/2018',\n",
       " 1666: '7/25/2018',\n",
       " 1667: '7/26/2018',\n",
       " 1668: '7/27/2018',\n",
       " 1669: '7/28/2018',\n",
       " 1670: '7/29/2018',\n",
       " 1671: '7/30/2018',\n",
       " 1672: '7/31/2018',\n",
       " 1673: '8/1/2018',\n",
       " 1674: '8/2/2018',\n",
       " 1675: '8/3/2018',\n",
       " 1916: '4/1/2019',\n",
       " 1917: '4/2/2019',\n",
       " 1918: '4/3/2019',\n",
       " 1919: '4/4/2019',\n",
       " 1920: '4/5/2019',\n",
       " 1921: '4/6/2019',\n",
       " 1922: '4/7/2019',\n",
       " 1963: '5/18/2019',\n",
       " 1964: '5/19/2019',\n",
       " 1965: '5/20/2019',\n",
       " 1966: '5/21/2019',\n",
       " 1967: '5/22/2019',\n",
       " 1968: '5/23/2019',\n",
       " 1969: '5/24/2019',\n",
       " 1970: '5/25/2019',\n",
       " 1971: '5/26/2019',\n",
       " 1972: '5/27/2019',\n",
       " 1973: '5/28/2019',\n",
       " 1974: '5/29/2019',\n",
       " 1975: '5/30/2019',\n",
       " 1976: '5/31/2019'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "dates={}\n",
    "\n",
    "for date in df[\"date\"]:\n",
    "    try:\n",
    "        datetime.datetime.strptime(date, '%d-%b-%y')\n",
    "    except ValueError:\n",
    "        dates[cnt] = date\n",
    "    cnt+=1\n",
    "    \n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have dates in multipe formats. I'll clean the day-Month-Year <code>%d-%B-%Y</code> format as an example. We can see that the entries for April 1st 2014 through April 10th 2014 are in this format. These are in row index 98 through row index 108."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>frequently_bought_together</th>\n",
       "      <th>lat_lon</th>\n",
       "      <th>purchase</th>\n",
       "      <th>related_items</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>61.33</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>100190</td>\n",
       "      <td>9-April-2014</td>\n",
       "      <td>dvd player</td>\n",
       "      <td>32.924,-96.547</td>\n",
       "      <td>tv</td>\n",
       "      <td>speakers</td>\n",
       "      <td>TX</td>\n",
       "      <td>75089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>90.48</td>\n",
       "      <td>household</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>100152</td>\n",
       "      <td>10-April-2014</td>\n",
       "      <td>drills</td>\n",
       "      <td>32.745,-96.46</td>\n",
       "      <td>tools</td>\n",
       "      <td>hammers</td>\n",
       "      <td>TX</td>\n",
       "      <td>75126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>86.52</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Houston</td>\n",
       "      <td>100103</td>\n",
       "      <td>11-April-2014</td>\n",
       "      <td>cookbook</td>\n",
       "      <td>29.72,-95.279</td>\n",
       "      <td>slow cooker</td>\n",
       "      <td>pot holders</td>\n",
       "      <td>TX</td>\n",
       "      <td>77012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>67.2</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>100194</td>\n",
       "      <td>12-April-2014</td>\n",
       "      <td>lens cleaner</td>\n",
       "      <td>40.093,-75.041</td>\n",
       "      <td>camera</td>\n",
       "      <td>editing software</td>\n",
       "      <td>PA</td>\n",
       "      <td>19115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>25.83</td>\n",
       "      <td>appliances</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>100130</td>\n",
       "      <td>13-April-2014</td>\n",
       "      <td>fruit</td>\n",
       "      <td>32.741,-117.244</td>\n",
       "      <td>blender</td>\n",
       "      <td>pitcher</td>\n",
       "      <td>CA</td>\n",
       "      <td>92107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>50.12</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>100152</td>\n",
       "      <td>14-April-2014</td>\n",
       "      <td>wax</td>\n",
       "      <td>32.745,-96.46</td>\n",
       "      <td>car wash</td>\n",
       "      <td>tire cleaner</td>\n",
       "      <td>TX</td>\n",
       "      <td>75126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>53.09</td>\n",
       "      <td>clothing</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>100140</td>\n",
       "      <td>15-April-2014</td>\n",
       "      <td>button down shirt</td>\n",
       "      <td>32.839,-117.262</td>\n",
       "      <td>shirts</td>\n",
       "      <td>t-shirt</td>\n",
       "      <td>CA</td>\n",
       "      <td>92037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>32.78</td>\n",
       "      <td>household</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>100172</td>\n",
       "      <td>16-April-2014</td>\n",
       "      <td>shampoo</td>\n",
       "      <td>37.189,-121.705</td>\n",
       "      <td>soap</td>\n",
       "      <td>body wash</td>\n",
       "      <td>CA</td>\n",
       "      <td>95103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>70.07</td>\n",
       "      <td>clothing</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>100152</td>\n",
       "      <td>17-April-2014</td>\n",
       "      <td>belt</td>\n",
       "      <td>32.745,-96.46</td>\n",
       "      <td>pants</td>\n",
       "      <td>jeans</td>\n",
       "      <td>TX</td>\n",
       "      <td>75126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>53.92</td>\n",
       "      <td>appliances</td>\n",
       "      <td>New York City</td>\n",
       "      <td>100181</td>\n",
       "      <td>18-April-2014</td>\n",
       "      <td>peanut butter</td>\n",
       "      <td>40.699,-74.041</td>\n",
       "      <td>toaster</td>\n",
       "      <td>butter</td>\n",
       "      <td>NY</td>\n",
       "      <td>10004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>99.06</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>100173</td>\n",
       "      <td>19-April-2014</td>\n",
       "      <td>gloves</td>\n",
       "      <td>39.953,-75.166</td>\n",
       "      <td>snow shovel</td>\n",
       "      <td>sand</td>\n",
       "      <td>PA</td>\n",
       "      <td>19102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amount     category           city  customer_id           date  \\\n",
       "98   61.33  electronics         Dallas       100190   9-April-2014   \n",
       "99   90.48    household         Dallas       100152  10-April-2014   \n",
       "100  86.52   appliances        Houston       100103  11-April-2014   \n",
       "101   67.2  electronics   Philadelphia       100194  12-April-2014   \n",
       "102  25.83   appliances      San Diego       100130  13-April-2014   \n",
       "103  50.12      outdoor         Dallas       100152  14-April-2014   \n",
       "104  53.09     clothing      San Diego       100140  15-April-2014   \n",
       "105  32.78    household       San Jose       100172  16-April-2014   \n",
       "106  70.07     clothing         Dallas       100152  17-April-2014   \n",
       "107  53.92   appliances  New York City       100181  18-April-2014   \n",
       "108  99.06      outdoor   Philadelphia       100173  19-April-2014   \n",
       "\n",
       "    frequently_bought_together          lat_lon     purchase  \\\n",
       "98                  dvd player   32.924,-96.547           tv   \n",
       "99                     drills     32.745,-96.46        tools   \n",
       "100                   cookbook    29.72,-95.279  slow cooker   \n",
       "101               lens cleaner   40.093,-75.041       camera   \n",
       "102                      fruit  32.741,-117.244      blender   \n",
       "103                        wax    32.745,-96.46     car wash   \n",
       "104          button down shirt  32.839,-117.262       shirts   \n",
       "105                    shampoo  37.189,-121.705         soap   \n",
       "106                       belt    32.745,-96.46        pants   \n",
       "107              peanut butter   40.699,-74.041      toaster   \n",
       "108                     gloves   39.953,-75.166  snow shovel   \n",
       "\n",
       "        related_items state  zip_code  \n",
       "98           speakers    TX     75089  \n",
       "99            hammers    TX     75126  \n",
       "100       pot holders    TX     77012  \n",
       "101  editing software    PA     19115  \n",
       "102           pitcher    CA     92107  \n",
       "103      tire cleaner    TX     75126  \n",
       "104           t-shirt    CA     92037  \n",
       "105         body wash    CA     95103  \n",
       "106             jeans    TX     75126  \n",
       "107            butter    NY     10004  \n",
       "108              sand    PA     19102  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[98:109]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clean these by applying the <code>.strftime()</code> method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "\n",
    "for date in df[\"date\"]:\n",
    "    try:\n",
    "        x = datetime.datetime.strptime(date, '%d-%B-%Y').strftime('%d-%b-%y')\n",
    "        df.loc[cnt, \"date\"] = x\n",
    "    except ValueError:\n",
    "        pass\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>frequently_bought_together</th>\n",
       "      <th>lat_lon</th>\n",
       "      <th>purchase</th>\n",
       "      <th>related_items</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>61.33</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>100190</td>\n",
       "      <td>09-Apr-14</td>\n",
       "      <td>dvd player</td>\n",
       "      <td>32.924,-96.547</td>\n",
       "      <td>tv</td>\n",
       "      <td>speakers</td>\n",
       "      <td>TX</td>\n",
       "      <td>75089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>90.48</td>\n",
       "      <td>household</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>100152</td>\n",
       "      <td>10-Apr-14</td>\n",
       "      <td>drills</td>\n",
       "      <td>32.745,-96.46</td>\n",
       "      <td>tools</td>\n",
       "      <td>hammers</td>\n",
       "      <td>TX</td>\n",
       "      <td>75126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>86.52</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Houston</td>\n",
       "      <td>100103</td>\n",
       "      <td>11-Apr-14</td>\n",
       "      <td>cookbook</td>\n",
       "      <td>29.72,-95.279</td>\n",
       "      <td>slow cooker</td>\n",
       "      <td>pot holders</td>\n",
       "      <td>TX</td>\n",
       "      <td>77012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>67.2</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>100194</td>\n",
       "      <td>12-Apr-14</td>\n",
       "      <td>lens cleaner</td>\n",
       "      <td>40.093,-75.041</td>\n",
       "      <td>camera</td>\n",
       "      <td>editing software</td>\n",
       "      <td>PA</td>\n",
       "      <td>19115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>25.83</td>\n",
       "      <td>appliances</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>100130</td>\n",
       "      <td>13-Apr-14</td>\n",
       "      <td>fruit</td>\n",
       "      <td>32.741,-117.244</td>\n",
       "      <td>blender</td>\n",
       "      <td>pitcher</td>\n",
       "      <td>CA</td>\n",
       "      <td>92107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>50.12</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>100152</td>\n",
       "      <td>14-Apr-14</td>\n",
       "      <td>wax</td>\n",
       "      <td>32.745,-96.46</td>\n",
       "      <td>car wash</td>\n",
       "      <td>tire cleaner</td>\n",
       "      <td>TX</td>\n",
       "      <td>75126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>53.09</td>\n",
       "      <td>clothing</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>100140</td>\n",
       "      <td>15-Apr-14</td>\n",
       "      <td>button down shirt</td>\n",
       "      <td>32.839,-117.262</td>\n",
       "      <td>shirts</td>\n",
       "      <td>t-shirt</td>\n",
       "      <td>CA</td>\n",
       "      <td>92037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>32.78</td>\n",
       "      <td>household</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>100172</td>\n",
       "      <td>16-Apr-14</td>\n",
       "      <td>shampoo</td>\n",
       "      <td>37.189,-121.705</td>\n",
       "      <td>soap</td>\n",
       "      <td>body wash</td>\n",
       "      <td>CA</td>\n",
       "      <td>95103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>70.07</td>\n",
       "      <td>clothing</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>100152</td>\n",
       "      <td>17-Apr-14</td>\n",
       "      <td>belt</td>\n",
       "      <td>32.745,-96.46</td>\n",
       "      <td>pants</td>\n",
       "      <td>jeans</td>\n",
       "      <td>TX</td>\n",
       "      <td>75126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>53.92</td>\n",
       "      <td>appliances</td>\n",
       "      <td>New York City</td>\n",
       "      <td>100181</td>\n",
       "      <td>18-Apr-14</td>\n",
       "      <td>peanut butter</td>\n",
       "      <td>40.699,-74.041</td>\n",
       "      <td>toaster</td>\n",
       "      <td>butter</td>\n",
       "      <td>NY</td>\n",
       "      <td>10004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>99.06</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>100173</td>\n",
       "      <td>19-Apr-14</td>\n",
       "      <td>gloves</td>\n",
       "      <td>39.953,-75.166</td>\n",
       "      <td>snow shovel</td>\n",
       "      <td>sand</td>\n",
       "      <td>PA</td>\n",
       "      <td>19102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amount     category           city  customer_id       date  \\\n",
       "98   61.33  electronics         Dallas       100190  09-Apr-14   \n",
       "99   90.48    household         Dallas       100152  10-Apr-14   \n",
       "100  86.52   appliances        Houston       100103  11-Apr-14   \n",
       "101   67.2  electronics   Philadelphia       100194  12-Apr-14   \n",
       "102  25.83   appliances      San Diego       100130  13-Apr-14   \n",
       "103  50.12      outdoor         Dallas       100152  14-Apr-14   \n",
       "104  53.09     clothing      San Diego       100140  15-Apr-14   \n",
       "105  32.78    household       San Jose       100172  16-Apr-14   \n",
       "106  70.07     clothing         Dallas       100152  17-Apr-14   \n",
       "107  53.92   appliances  New York City       100181  18-Apr-14   \n",
       "108  99.06      outdoor   Philadelphia       100173  19-Apr-14   \n",
       "\n",
       "    frequently_bought_together          lat_lon     purchase  \\\n",
       "98                  dvd player   32.924,-96.547           tv   \n",
       "99                     drills     32.745,-96.46        tools   \n",
       "100                   cookbook    29.72,-95.279  slow cooker   \n",
       "101               lens cleaner   40.093,-75.041       camera   \n",
       "102                      fruit  32.741,-117.244      blender   \n",
       "103                        wax    32.745,-96.46     car wash   \n",
       "104          button down shirt  32.839,-117.262       shirts   \n",
       "105                    shampoo  37.189,-121.705         soap   \n",
       "106                       belt    32.745,-96.46        pants   \n",
       "107              peanut butter   40.699,-74.041      toaster   \n",
       "108                     gloves   39.953,-75.166  snow shovel   \n",
       "\n",
       "        related_items state  zip_code  \n",
       "98           speakers    TX     75089  \n",
       "99            hammers    TX     75126  \n",
       "100       pot holders    TX     77012  \n",
       "101  editing software    PA     19115  \n",
       "102           pitcher    CA     92107  \n",
       "103      tire cleaner    TX     75126  \n",
       "104           t-shirt    CA     92037  \n",
       "105         body wash    CA     95103  \n",
       "106             jeans    TX     75126  \n",
       "107            butter    NY     10004  \n",
       "108              sand    PA     19102  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[98:109]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that we've cleaned these dates to the correct format.\n",
    "\n",
    "There's dates in other formats as well.\n",
    "\n",
    "In these files, more data can be made consistent but here only shown as examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
2 - Missing Values
In this second step I'll show you how to detect and clean missing values in the purchase column.

You will see: comment of action, python code and results.

import pandas as pd

df = pd.read_json("customer_data.json", convert_dates = False)
df.head()
<style scoped> .dataframe tbody tr th:only-of-type { vertical-align: middle; }
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</style>
amount	category	city	customer_id	date	frequently_bought_together	lat_lon	purchase	related_items	state	zip_code
0	24.64	household	Chicago	100191	1-Jan-14	towels	41.86,-87.619	soap	towels	IL	60605
1	35	clothing	Dallas	100199	2-Jan-14	sandals	32.924,-96.547	shorts	belts	TX	75089
2	89.72	outdoor	Philadelphia	100170	3-Jan-14	lawn bags	40.002,-75.118	lawn_mower	shovels	PA	19019
3	51.32	electronics	Chicago	100124	4-Jan-14	headphones	41.88,-87.63	laptop	headphones	IL	60603
4	81.75	outdoor	Philadelphia	100173	5-Jan-14	sponge	39.953,-75.166	car wash	sponge	PA	19102
Taking a look at unique values, and missing values.

The .isna() method will only find standard missing value types, so we'll need to use the .unique() method for identifying non-standard missing values.

print(df["purchase"].unique())
print(sum(df["purchase"].isna()))
['soap' 'shorts' 'lawn_mower' 'laptop' 'car wash' 'lawn mower' 'grill'
 'household cleaner' 'slow cooker' 'camera' 'snow shovel' 'shoes'
 'blender' 'shirts' 'toaster' 'detergent' 'tv' 'paper products' 'tools'
 'pants' 'audio' 'microwave' 'food processor' 'jackets' 'cell phone'
 'flower pot' None '?' '__' 'na' '--' 'cell' 'cell_phone' 'lawnmower'
 '1111']
36
Lets change the standard missing values to a new category called unavailable.

We can double check that it worked by summing for missing values using the .isna() method after we've changed the missing values using the .fillna() method. If it worked, the sum should be 0.

We can also take a look at the unique values again to see if this new unavailable shows up.

# changing standard missing values to "unavailable"
df["purchase"].fillna("unavailable", inplace=True)

# double checking that it worked by summing for missing values, and looking at unique categories
print(sum(df["purchase"].isna()))
print(df["purchase"].unique())
0
['soap' 'shorts' 'lawn_mower' 'laptop' 'car wash' 'lawn mower' 'grill'
 'household cleaner' 'slow cooker' 'camera' 'snow shovel' 'shoes'
 'blender' 'shirts' 'toaster' 'detergent' 'tv' 'paper products' 'tools'
 'pants' 'audio' 'microwave' 'food processor' 'jackets' 'cell phone'
 'flower pot' 'unavailable' '?' '__' 'na' '--' 'cell' 'cell_phone'
 'lawnmower' '1111']
We can see several non-standard missing value types.

Lets identify those by using a list of missing_values which contains the following ["?", "__", "na", "--"].

We'll replace them by looping through the purchase column, and replacing the non-standard missing values using the .loc() method.

# list of non-standard missing values
missing_values = ["?", "__", "na", "--"]

# replacing the missing values with the new category, "unavailable"
cnt = 0
for i in df["purchase"]:
    if i in missing_values:
        df.loc[cnt, "purchase"] = "unavailable"
    cnt+=1

print(df["purchase"].unique())
['soap' 'shorts' 'lawn_mower' 'laptop' 'car wash' 'lawn mower' 'grill'
 'household cleaner' 'slow cooker' 'camera' 'snow shovel' 'shoes'
 'blender' 'shirts' 'toaster' 'detergent' 'tv' 'paper products' 'tools'
 'pants' 'audio' 'microwave' 'food processor' 'jackets' 'cell phone'
 'flower pot' 'unavailable' 'cell' 'cell_phone' 'lawnmower' '1111']
We could also convert missing values when we read in the data.

The .read_json() method does not have the na_values parameter like .read_csv() does.

We'll need to read in the json file, convert it to a csv file, and then read it back in using .read_csv().

# reading in the json file
df = pd.read_json("customer_data.json", convert_dates = False)

# writing the json file to a csv file
df.to_csv("customer_data2.csv")

# reading the csv file back in, replacing missing values
df2 = pd.read_csv("customer_data2.csv", na_values=missing_values)

print(df2["purchase"].unique())
['soap' 'shorts' 'lawn_mower' 'laptop' 'car wash' 'lawn mower' 'grill'
 'household cleaner' 'slow cooker' 'camera' 'snow shovel' 'shoes'
 'blender' 'shirts' 'toaster' 'detergent' 'tv' 'paper products' 'tools'
 'pants' 'audio' 'microwave' 'food processor' 'jackets' 'cell phone'
 'flower pot' nan 'cell' 'cell_phone' 'lawnmower' '1111']
The non-standard missing values have all been changed to missing values.

Lets finish up by replacing the missing values with the new category, unavailable.

# changing missing values to "unavailable"
df2["purchase"].fillna("unavailable", inplace=True)

# double checking that it worked by summing for missing values, and looking at unique categories
print(sum(df2["purchase"].isna()))
print(df2["purchase"].unique())
0
['soap' 'shorts' 'lawn_mower' 'laptop' 'car wash' 'lawn mower' 'grill'
 'household cleaner' 'slow cooker' 'camera' 'snow shovel' 'shoes'
 'blender' 'shirts' 'toaster' 'detergent' 'tv' 'paper products' 'tools'
 'pants' 'audio' 'microwave' 'food processor' 'jackets' 'cell phone'
 'flower pot' 'unavailable' 'cell' 'cell_phone' 'lawnmower' '1111']
